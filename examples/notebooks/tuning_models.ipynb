{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tuning Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages\n",
    "\n",
    "Let us import dffml and other packages that we might need."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from dffml import *\n",
    "import contextlib\n",
    "import logging\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use asyncio in a notebook, we need to use nest_asycio.apply()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build our Dataset\n",
    "\n",
    "dffml.util has a very convinient function [cached_download()](../../api/util/net.rst#dffml.util.net.cached_download) that can be used to download datasets and make sure you don't download them if you have already.\n",
    "\n",
    "\n",
    "The cached_download() has the following parameters:\n",
    "\n",
    "\n",
    "\n",
    "1. `url` (str) – The URL to download\n",
    "\n",
    "2. `target_path` (str, pathlib.Path) – Path on disk to store download\n",
    "\n",
    "3. `expected_hash` (str) – SHA384 hash of the contents\n",
    "\n",
    "4. `protocol_allowlist` (list, optional) – List of strings, one of which the URL must start with. \n",
    "   We won't be using this in our case.\n",
    "          \n",
    "Don't forget to calculate the `expected_hash`, you can find out how at [cached_download()](../../api/util/net.rst#dffml.util.net.cached_download)!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_path = await cached_download(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    \"wine_quality.csv\",\n",
    "    \"789e98688f9ff18d4bae35afb71b006116ec9c529c1b21563fdaf5e785aea8b3937a55a4919c91ca2b0acb671300072c\",\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In Dffml, we try to use asynchronicity where we can, to get that extra bit of performance. Let's use the async version of load() to load the dataset that we just downloaded into a source. We can easily achieve this by declaring a [CSVSource](../../api/source/csv.rst) with the `data_path` and the `delimiter` value since the data we downloaded seems to have a non-comma delimiter.\n",
    "\n",
    "After that, we can just create an array of records by loading each one through the load() function.\n",
    "\n",
    "Feel free to also try out the no async version of load()."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "async def load_dataset(data_path):\n",
    "    data_source = CSVSource(filename=data_path, delimiter=\";\")\n",
    "    data = [record async for record in load(data_source)]\n",
    "    return data\n",
    "\n",
    "\n",
    "data = asyncio.run(load_dataset(data_path))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dffml lets you visualize a record in quite a neat fashion. Lets have a look."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(data[0], \"\\n\")\n",
    "print(len(data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\tKey:\t0\n",
      "                           Record Features\n",
      "+----------------------------------------------------------------------+\n",
      "|  fixed acidity  |                        7.4                         |\n",
      "+----------------------------------------------------------------------+\n",
      "| volatile acidity|                        0.7                         |\n",
      "+----------------------------------------------------------------------+\n",
      "|   citric acid   |                         0                          |\n",
      "+----------------------------------------------------------------------+\n",
      "|  residual sugar |                        1.9                         |\n",
      "+----------------------------------------------------------------------+\n",
      "|    chlorides    |                       0.076                        |\n",
      "+----------------------------------------------------------------------+\n",
      "|free sulfur dioxi|                         11                         |\n",
      "+----------------------------------------------------------------------+\n",
      "|total sulfur diox|                         34                         |\n",
      "+----------------------------------------------------------------------+\n",
      "|     density     |                       0.9978                       |\n",
      "+----------------------------------------------------------------------+\n",
      "|        pH       |                        3.51                        |\n",
      "+----------------------------------------------------------------------+\n",
      "|    sulphates    |                        0.56                        |\n",
      "+----------------------------------------------------------------------+\n",
      "|     alcohol     |                        9.4                         |\n",
      "+----------------------------------------------------------------------+\n",
      "|     quality     |                         5                          |\n",
      "+----------------------------------------------------------------------+\n",
      "                                           Prediction:    Undetermined \n",
      "\n",
      "1599\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets split our dataset into train and test splits."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_data = data[320:]\n",
    "test_data = data[:320]\n",
    "print(len(data), len(train_data), len(test_data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1599 1279 320\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "!rm -rf \"scikitsvc\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate our Models with parameters\n",
    "\n",
    "Dffml makes it quite easy to load models dynamically using the `Model.load()` function. All the entrypoints for models available in DFFML can be found at the [Model Plugins Page](../../plugins/dffml_model.rst). After that, you just have to parameterize the loaded models and they are ready to train!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "XGBCModel = Model.load(\"xgbclassifier\")\n",
    "\n",
    "features = Features(\n",
    "    Feature(\"fixed acidity\", int, 1),\n",
    "    Feature(\"volatile acidity\", int, 1),\n",
    "    Feature(\"citric acid\", int, 1),\n",
    "    Feature(\"residual sugar\", int, 1),\n",
    "    Feature(\"chlorides\", int, 1),\n",
    "    Feature(\"free sulfur dioxide\", int, 1),\n",
    "    Feature(\"total sulfur dioxide\", int, 1),\n",
    "    Feature(\"density\", int, 1),\n",
    "    Feature(\"pH\", int, 1),\n",
    "    Feature(\"sulphates\", int, 1),\n",
    "    Feature(\"alcohol\", int, 1),\n",
    ")\n",
    "\n",
    "predict_feature = Feature(\"quality\", int, 1)\n",
    "model = XGBCModel(\n",
    "    features=features,\n",
    "    predict= predict_feature,\n",
    "    location=\"xgbc\",\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train our Models\n",
    "Finally, our models are ready to be trained using the `high-level` API. Let's make sure to pass each record as a parameter by simply using the unpacking operator(*)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "await train(model, *train_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test our Models\n",
    "\n",
    "To test our model, we'll use the `accuracy()` function in the `high-level` API.\n",
    "\n",
    "We ask for the accuracy to be assessed using the classification accuracy by passing \"acscore\" to `AccuracyScorer.load()`. You can find all the scorer entrypoints at the [Scorers page](../../plugins/dffml_accuracy.rst)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "AccScore = AccuracyScorer.load(\"acscore\")\n",
    "scorer = AccScore()\n",
    "accuracy1 = await accuracy(model, scorer, predict_feature, *test_data)\n",
    "print(\"Accuracy:\", accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.575\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Models\n",
    "\n",
    "\n",
    "Let's try to tune out models by mutating the hyperparameters in the config of the model. You can find a list of mutable parameters in docs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with model.config.no_enforce_immutable():\n",
    "    model.config.learning_rate = 0.2\n",
    "    model.config.n_estimators = 200\n",
    "    model.config.max_depth = 3\n",
    "await train(model, *train_data)\n",
    "accuracy1 = await accuracy(model, scorer, predict_feature, *test_data)\n",
    "print(\"Accuracy:\", accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Parameter Grid**\n",
    "\n",
    "Tuning models can be demanding if done manually.\n",
    "Let us define a Parameter Grid and call the `optimize()` function through the context to tune the Hyperparameters.\n",
    "\n",
    "Before that, let's set output to logging info so we know whats happening in the parameter grid."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from dffml.accuracy import MeanSquaredErrorAccuracy\n",
    "from dffml.optimizer import ParameterGrid\n",
    "\n",
    "parameter_optim = ParameterGrid(\n",
    "    parameters = {\n",
    "        \"learning_rate\" : [0.2, 0.3, 0.4, 0.5],\n",
    "        \"n_estimators\" : [50, 100, 150, 200],\n",
    "        \"max_depth\" : [3, 4, 5, 6, 8],\n",
    "    }\n",
    ")\n",
    "async with contextlib.AsyncExitStack() as astack:\n",
    "    optimizer = await astack.enter_async_context(parameter_optim)\n",
    "    octx = await astack.enter_async_context(optimizer())\n",
    "\n",
    "tuned_accuracy1 = await octx.optimize(model, predict_feature, scorer, train_data, test_data)\n",
    "print(\"Tuned Accuracy:\", tuned_accuracy1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:root:Optimizing model with parameter grid: {'learning_rate': [0.2, 0.3, 0.4, 0.5], 'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 4, 5, 6, 8]}\n",
      "INFO:root:['learning_rate', 'n_estimators', 'max_depth']\n",
      "INFO:root:(0.2, 50, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.565625\n",
      "INFO:root:(0.2, 50, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.571875\n",
      "INFO:root:(0.2, 50, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.5875\n",
      "INFO:root:(0.2, 50, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.2, 50, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.571875\n",
      "INFO:root:(0.2, 100, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.54375\n",
      "INFO:root:(0.2, 100, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.2, 100, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.596875\n",
      "INFO:root:(0.2, 100, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.2, 100, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.565625\n",
      "INFO:root:(0.2, 150, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.540625\n",
      "INFO:root:(0.2, 150, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.2, 150, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.578125\n",
      "INFO:root:(0.2, 150, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.584375\n",
      "INFO:root:(0.2, 150, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.565625\n",
      "INFO:root:(0.2, 200, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.55\n",
      "INFO:root:(0.2, 200, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.2, 200, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.5875\n",
      "INFO:root:(0.2, 200, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.2, 200, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.553125\n",
      "INFO:root:(0.3, 50, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.3, 50, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.3, 50, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.3, 50, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.58125\n",
      "INFO:root:(0.3, 50, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.590625\n",
      "INFO:root:(0.3, 100, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.3, 100, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.578125\n",
      "INFO:root:(0.3, 100, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.5875\n",
      "INFO:root:(0.3, 100, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.3, 100, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.3, 150, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.546875\n",
      "INFO:root:(0.3, 150, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.3, 150, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.584375\n",
      "INFO:root:(0.3, 150, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.571875\n",
      "INFO:root:(0.3, 150, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.565625\n",
      "INFO:root:(0.3, 200, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.55625\n",
      "INFO:root:(0.3, 200, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.58125\n",
      "INFO:root:(0.3, 200, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.571875\n",
      "INFO:root:(0.3, 200, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.3, 200, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.4, 50, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.4, 50, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.578125\n",
      "INFO:root:(0.4, 50, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.59375\n",
      "INFO:root:(0.4, 50, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.58125\n",
      "INFO:root:(0.4, 50, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.590625\n",
      "INFO:root:(0.4, 100, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.4, 100, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.584375\n",
      "INFO:root:(0.4, 100, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.58125\n",
      "INFO:root:(0.4, 100, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.4, 100, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.578125\n",
      "INFO:root:(0.4, 150, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.4, 150, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.603125\n",
      "INFO:root:(0.4, 150, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.571875\n",
      "INFO:root:(0.4, 150, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.4, 150, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.4, 200, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.4, 200, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.6\n",
      "INFO:root:(0.4, 200, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.546875\n",
      "INFO:root:(0.4, 200, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.553125\n",
      "INFO:root:(0.4, 200, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.5, 50, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.546875\n",
      "INFO:root:(0.5, 50, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.5, 50, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.540625\n",
      "INFO:root:(0.5, 50, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.56875\n",
      "INFO:root:(0.5, 50, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.5, 100, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.5375\n",
      "INFO:root:(0.5, 100, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.5, 100, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.54375\n",
      "INFO:root:(0.5, 100, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.578125\n",
      "INFO:root:(0.5, 100, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.55625\n",
      "INFO:root:(0.5, 150, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.5, 150, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.575\n",
      "INFO:root:(0.5, 150, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.540625\n",
      "INFO:root:(0.5, 150, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.5, 150, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.5, 200, 3)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.5, 200, 4)\n",
      "INFO:root:Accuracy of the tuned model: 0.559375\n",
      "INFO:root:(0.5, 200, 5)\n",
      "INFO:root:Accuracy of the tuned model: 0.540625\n",
      "INFO:root:(0.5, 200, 6)\n",
      "INFO:root:Accuracy of the tuned model: 0.5625\n",
      "INFO:root:(0.5, 200, 8)\n",
      "INFO:root:Accuracy of the tuned model: 0.5375\n",
      "INFO:root:\n",
      "Optimal Hyper-parameters: {'learning_rate': 0.4, 'n_estimators': 150, 'max_depth': 4}\n",
      "INFO:root:Accuracy of Optimized model: 0.603125\n",
      "Tuned Accuracy: 0.603125\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Visualize the Accuracies**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar([\"model\", \"tuned_model\"], [accuracy1,tuned_accuracy1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}