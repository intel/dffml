Initial thoughts formed by strategic plans kickstarted at beginning of context kick off. They begin spinning off thoughts (system contexts) which could be moved from start k8s start to template spec state. These are passed to the gatekeeper and then to the prioritizer. Other strategic plans can accept outputs of strategic plans and then generate better guesses at system context. We are guessing at the chemical equation required to satisfy the seed input (the voice command). The prioritizer is trying all ideas it can in order to satisfy the request. Some it really executes, some it just thinks about and does accuracy calculations across nested startigc plan predictions given best guess seed inputs using available resources through operations to achive outputs that satisfy agent, organizational, and requestor statigic plans (withing yhe top level systems context)

on k8s crd creation we effectively have an Alice start which is given system context. These inputs are feed to stratigic plans as described above. The prioritizer decides what system contexts it wants to try executing for real and what ones it just wants to think about. By default in effect we run in safe mode. No execution. No reaction. Just hypothesize. All the strategic plans in those system context thoughts? Call their predict method. When you do that. Youâ€™ll be relying on models trained from input output values of saved cached system contexts.  Files saved. 

We need to be rerunning the accuracy on the strategic plan model after every execution. This will have the effect that in Flash Boys where everyone wanted to recreate the SEC approved something number so they could abitrare faster than the latency of the time it took others without the model to see the new price. We want to predict dataflows that satisfy the output constraints. We do this by using our stratigic plan to I/O models.

if everything is a encoder then create encoder/decoder models on all permutations of inputs and outputs across stratigic plans and system context I/O


We can leverage task 2: caching to use sources to map input values within system contexts including strategic plan inputs and outputs into dataset sources. We can leverage dataflows to modify data in different ways as it is saved to and loaded from the cache. For example run inputs with locality of file through uploads to blob storage or personal datastore. Then create references in db A and update references used in 

play with DIDs and personal datastores before making any input networks. Create proxies from web2 to web3 which are DFFML agnostic but are packaged as dffml-service-web3-did|datastore|relay|bdrige-irc|smtp etc.