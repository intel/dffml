- by putting everything in the web3 space we can hotswap anything within our supply chain simply by supporting serializtion (a gateway) to and from that ibterface (plus transport to relavent chain(s)). Consider web3/odap/peer dids and did methods as the serializatipn format whoch the open architecture is based on. The common application transport portocol. We are defining a layer 8. A thought transport protocol. Where thoughts are executed, recalled from memory, hypothsised, etc. Where a thought is a system context is a dataflow. By doing this atop ODAP (we are also looking at KERI, its not really important what one uses underneath we should call put certain properties of technologies which make them suitable for implementation of this methodology, and give example protocols which one could huild this on, its like how you *can* use wheels and pip to distribute anything but do you want to? Me yes, you maybe want to do it with dpkg, great, sure even the open archecture itself will have an open architecture format architecture. Its all about what can ypu hotswap anyway) achieve interoperability with the web3 ecosystem
- we’re going to put out software supply chain into this distributed model because IT IS DISTRIBUTED. Just in the same that our source code is distributed. Because we need context. Language is contextual, inflection makes one phrase the opposite meaning of the same phrase said with different inflection. This notion of context inherently lends itself towards distributed solutions because context has locality. If we want a truly functional language we must incorporate all context into the language (the open architecture, our shared language with the machine, and can be used to translate therefore into different languages and cultures due to contextual understanding). So what are we doing. Well in a way we’re making everything functional, but in reality we can’t make everything functional so we build models to predict the unknown states between the known states. This allows us to optimize “motor control” skills, muscle memory. The kick is that your brain is a muscle. Its the orchestrator, but on a way its not the only orchestrator. Let us think about the subconscious. An example closer to the concious to start, Dejavu for instance, we think we remember something but we don’t, or do we? What happened. A strategic plan saw a new system context come in. Another strategic plan which takes that as an input. Everything is a conceptual layer because we train across the whole strategic plan feature permutation set, conceptual layer seems more like just any layer which a strategic plan ends up in within the strategic neural network. Well we usually operate on inference. Like walking, its 2nd nature. (Second nature, fluent). What are we doing, we’re training those permutation models across at all times! Our brain (and Alice’s will) simply continually scans for important information. As aligned with strategic principles (what keeps you alive, what lets you sleep at night). All the previous system contexts are held in the cache. Well what is the cache, well its all neurons. Because the graph based neuron architecture (dataflows plus models as neural networks trained across planes) when hooked up to control is a distributed generic architecture where data and compute are represented via a common protocol (neurons firing). Response is asynchronous and potentially will lie dormant triggered on accident modifying state used elsewhere. Because it is a distributed system. A fail safe data centric distributed system. We will also used a shared representation for data as compute (infrastructure as code principles under the hold do setup of resources, operations modify to achieve  desired state). This architecture scales up but is subject to inherent limitations on control signal speed. The name of the game becomes speed and effectiveness of communication. You can have all the compute in the world but if it doesn’t connect to control to do feedback on its sum of knowledge (or via aggregation methods, same thing). Then what use is it. What is the response time with human in the loop? What is the level of criticality where we take the human out of the loop? What decisions should Alice never make? We need to ask these questions and brainstorm. These will lead us to our failsafe conceptual models. We can then incentivize Alices paterns of thought so that she achives high accuracy trains of rhought for usage of fail safes within hypothetical situations. She will then tune these pretrained models on the fly when she find iut what her controls are later within the context of the situation where it becomes applicable. But how does all of this relate to dejavu? Well it’s because we missfired on an aligned system context. We got a half memory sent to the top level. Why? Maybe because the current system context looks like something we’ve seen before, or a combination of something’s we’ve seen before. This is an error condition! Sure it can be good, there is some chaos metric which is healthy at any point in a train of system contexts lifespan. It stimulates other misfiring nueones. Remember there are some state machines in there. Data as compute, stale cache references may accidentally retrive while routines connected to control. The point of it all is expect misfires since we are usually operating in infernece. What are the control checks, the provenance info, we need to endure no misfires end up fatal. What stattegic olans do we need to ensure our active for each top level context deending on licality and how do we determine that. Wel we dobit the same way as we practiced our new skill in our head. We train those models and when we know the system context, we execute and do active learning on the fly to weed out potentially malicious inputs. Like your watching the coach do a move and then your doing it in your head then you drill with your partner then you roll, context is different, but you apply thise models and learn on the fly. Alice will too. The open architecture faciltates the tranfer of thoughts so as to achive execution with intent.
- Peer dids as repreeation of git commits be signs so we can actually do a gateway for our source as web3 just by implementing the reverse of our scanners
- We just parse existing ci system to get their data into web3 and then execute peoces in them using dids of overlays for applied ptches over upstream of repos which are just the dods we do the cross cherry pick on to form traisn of thought whoch we tag as to be executed and the distributed execution environment just picks it up so long as it has all the seven other layers of the OSI stack statisfied. Then it can do its layer 8 thought communication above that. Which is the execution pf tje ci/cd jobs. Or just the applied itself. Or anything. Alice. It will be Alice because it’s all Alice, Alice is the entity and the architecture and the infrastructure. Because the protocol is the same. The Open Architecture. An extensible protocol for communication of thoughts. Layer 8 in the OSI stack. (It’s just ML + networking)