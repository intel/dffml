- by putting everything in the web3 space we can hotswap anything within our supply chain simply by supporting serializtion (a gateway) to and from that ibterface (plus transport to relavent chain(s)). Consider web3/odap/peer dids and did methods as the serializatipn format whoch the open architecture is based on. The common application transport portocol. We are defining a layer 8. A thought transport protocol. Where thoughts are executed, recalled from memory, hypothsised, etc. Where a thought is a system context is a dataflow. By doing this atop ODAP (we are also looking at KERI, its not really important what one uses underneath we should call put certain properties of technologies which make them suitable for implementation of this methodology, and give example protocols which one could huild this on, its like how you *can* use wheels and pip to distribute anything but do you want to? Me yes, you maybe want to do it with dpkg, great, sure even the open archecture itself will have an open architecture format architecture. Its all about what can ypu hotswap anyway) achieve interoperability with the web3 ecosystem
- we’re going to put out software supply chain into this distributed model because IT IS DISTRIBUTED. Just in the same that our source code is distributed. Because we need context. Language is contextual, inflection makes one phrase the opposite meaning of the same phrase said with different inflection. This notion of context inherently lends itself towards distributed solutions because context has locality. If we want a truly functional language we must incorporate all context into the language (the open architecture, our shared language with the machine, and can be used to translate therefore into different languages and cultures due to contextual understanding). So what are we doing. Well in a way we’re making everything functional, but in reality we can’t make everything functional so we build models to predict the unknown states between the known states. This allows us to optimize “motor control” skills, muscle memory. The kick is that your brain is a muscle. Its the orchestrator, but on a way its not the only orchestrator. Let us think about the subconscious. An example closer to the concious to start, Dejavu for instance, we think we remember something but we don’t, or do we? What happened. A strategic plan saw a new system context come in. Another strategic plan which takes that as an input. Everything is a conceptual layer because we train across the whole strategic plan feature permutation set, conceptual layer seems more like just any layer which a strategic plan ends up in within the strategic neural network. Well we usually operate on inference. Like walking, its 2nd nature. (Second nature, fluent). What are we doing, we’re training those permutation models across at all times! Our brain (and Alice’s will) simply continually scans for important information. As aligned with strategic principles (what keeps you alive, what lets you sleep at night). All the previous system contexts are held in the cache. Well what is the cache, well its all neurons. Because the graph based neuron architecture (dataflows plus models as neural networks trained across planes) when hooked up to control is a distributed generic architecture where data and compute are represented via a common protocol (neurons firing). Response is asynchronous and potentially will lie dormant triggered on accident modifying state used elsewhere. Because it is a distributed system. A fail safe data centric distributed system. We will also used a shared representation for data as compute (infrastructure as code principles under the hold do setup of resources, operations modify to achieve  desired state). This architecture scales up but is subject to inherent limitations on control signal speed. The name of the game becomes speed and effectiveness of communication. You can have all the compute in the world but if it doesn’t connect to control to do feedback on its sum of knowledge (or via aggregation methods, same thing). Then what use is it. What is the response time with human in the loop? What is the level of criticality where we take the human out of the loop? What decisions should Alice never make? We need to ask these questions and brainstorm. These will lead us to our failsafe conceptual models. We can then incentivize Alices paterns of thought so that she achives high accuracy trains of rhought for usage of fail safes within hypothetical situations. She will then tune these pretrained models on the fly when she find iut what her controls are later within the context of the situation where it becomes applicable.