NOtes: Read transcription, predict context changes (visually similar blobs, use text as image as CNN object segemntation techniques, where segmenations is 2x2 labels which are I/O of strategic plans) predict question, answer question, this is the bullet point version (these are the paths we can go down next, they are dynamic because we can choose to apply different strategic plans on the fly to "see" the way the meeting relates agent inititative invovlement wise, innersource, dev pull model, 2/3ndparty CI/CD). Indented points are the conceputally similar blobs via the most context approproate phologenay while applying organizational desires in mind in terms of provenance on what other phologenays it must fall in (required strategic plans as requested by interacted with agents, agreed upon operating model within ad-hoc formed organization). Essentially user configurable inputs to prioritizer and then the final prioritoizations is the meeting name and time and attendties to define the effectivly exetuing top level system context (cli invokation to join meeting, notes meeting title, record.key). This allows us to visualize the meeting as notes, as an interactive VR scene with characters talking, as whatever we want. We use output operations make the context the "framerate" of the audio. What people are saying what words in that frame, how does that relate to other concepts you know Alice? Do you know who each one is, could you slice the audio to mute a sound in postprocessing on the live stream? Should be easy with they way sources are set up, just have to take a video stream, preprocess into and audio stream, ensure prirotiizer yields frames in order to `dfpreprocess.records()`, then use this notes based algorthim to slice it and dice it any way you want it.