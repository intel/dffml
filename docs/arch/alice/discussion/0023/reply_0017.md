Certain brain pathways do not fire sometimes or for some agents. When they do they have a value. This is like the gatekeeper and the prioritizer. When used in either prediction mode or live execution mode. Strategic plans inputs are the inputs that should trigger things. Like a slip of the tongue would be caused by an incorrect classification from the gatekeeper. It failed to take some strategic plan into account that would have stopped the slip. We may be able to trace that via lack of provenance or we might be able to theorize based on encoder decoder models from labeled “human” perspective data “energy,vibe,feel,subjective data” mapped to other historical outputs from system context chains/trains. Where the labels are joined with the historical data so as to have manually classified each one. Of course we can write strategic plans to prompt user for input or we can write additional strategic plans which run on dataflow as class context entry (autostart background context from overlay, something like seed but for contexts? Enter the context of the dataflow as class immediately start the background context. We’ll provide defaults people can extend like classes and subclass on `__new__()` will do dataflow as class with the subclass dataflow overlayed on top of the parents using MRO from inspect. ‘_ext’ sphinx extension to extend automodule/class stuff to output class dataflows as mermaid and enable editing when rendered