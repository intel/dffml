- The Open Architecture enables hybrid on/off chain smart contacts.
  - It does this by incorporating risk management into architecture definition / smart contract.
    - Strategic plans work with the gatekeeper and prioritizer to negotiate and execute off chain contracts.
    - Models within strategic plans are involved in risk tolerance.
  - Smart contracts with understanding of risk are effectively entities making decisions based on models. This allows for mutation in implementation while maintaining principles.
    - The smart contract is able to make its own decisions based on learned experience (models) so as to continue to operate until its strategic goals are meet. As measured by oracle data ordained from trusted parties as is applicable to context. Where chains of trust are established via Peer DIDs between entities and data for provenance. Leveraging verifiable credentials (opencert) for review system to measure risk in absence of attestation.
- For trains of thought at critical velocity. Fully optimized resource utilization to optimally progress train of thought to move strategic principles in correct directions and advance the “state of the art” for any given conceptual field. A/B feature branch permutation testing to sus out bleeding edge to determine system context which is the optimal selection of overlays where overlays are forks, branches, similar repos, similar projects, similar specs, similar working groups, similar goals, similar strategic plans, similar strategic principles, priorities. Autoencoders trained against input data for system context with high accuracy represent.
- This set of operations used maps to these strategic plan output through conceptual layers. Could use classification model to buckeize into key value map then lookup image, ir other data and output that. So this is like saying i have a cached system context where i want to visualize the codebase as if it was a cartoon character. We then classify manually or via strategic plans which suggest classifications. Which codebases are similar to which characters. We then run feature extraction operations / strategic plans which suggest system contexts to do feature extraction based on definition aka input parent linage / locality / primitive. This means what data flows can we make where the data on either side of the manual classification is taken as inputs. Do this for each side. Filter down to valid flows as defined by possible routes of inputs within parent system context to inputs of operations in suggested flows. This is similar to making a balanced chemical equation. Again using out analogy of the chemical equation. We build a encoder/decoder models of all permutations of strategic to strategic and other inputs (each unique liniage as a record). So you could have an input which says which codebase is this similar too. Good, bad, unsure. Then a label for cartoon characters with good bad unsure. Then run feature extraction on each. After auto encoder modules are built
- Universal translator with understanding of meaning. Map one representation to another by thinking up as many system contexts as possible which describe each representation. All possible features we can extract. All possible dataflows we can build by wiring together different compatible types by creating all permutations of all interfaces including nesting. During building of complete set filter to valid system contexts checking possible routings of inputs within parent system context or ability to create from those.
- Distributed network of metric collectors. Of security information we should feed into cve bin tool. Maybe start by creating checker entrypoint for a checker which knows it’s running under a dataflow. Could execute using runpy with opimp self in globals. OpImp shared config property of object which is dataflow as class which listens for new vuln info for checker in background when instantiated. When a new vuln is detected we could trigger a scan on all previously scanned atrifacts for which we had scanned before by having a strategic plan overlayed on a long running flow which inspects historical contexts which executed scans against checker came up as exists within file scanned. Use this presence of existence within previous scans to query off chain data from historical system contexts. To build next contexts where results of scan opperatuon are removed so that running results in latest vuln info being incorporated into scan. This is analogous to dev pull model when new commit on branch released. Do scan rerun is same as redoing A/B feature testing of commits.
- Prioritizer opportunity cost factor in value of data extracted from running self vs cost to contract and loss of data value. Data value measured by historical instances where output of the model was found to have strong correlation with positive changes in strategic principles. Then map those principles via conceptual translation model to measure(s) of value to compare apples to apples in terms of cost to execute self vs contract.
- What will Alice do?
  - Architect
  - DJ
  